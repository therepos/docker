services:
  pdfai:
    image: ghcr.io/therepos/pdfai-b:latest
    container_name: pdfai
    restart: unless-stopped
    environment:
      - OLLAMA_SERVICE=ollama # Indicate the name of Ollama service
      - OLLAMA_MODEL=mistral  # Default model
    volumes:
      - /mnt/sec/apps/pdfai/data:/app/data
      - /mnt/sec/apps/pdfai/faiss_index:/app/faiss_index
    ports:
      - "3024:8000"
    networks:
      - OLLAMA_NETWORK=ollama-network  # Use the same network as Ollama service

networks:
  ollama-network:
    external: true  # Default network fallback
